{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084c90f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training LSTM ---\n",
      "\n",
      "Epoch 01 | Train MSE: 0.378359 | Val MSE: 0.401785\n",
      "Epoch 02 | Train MSE: 0.327668 | Val MSE: 0.332391\n",
      "Epoch 03 | Train MSE: 0.291570 | Val MSE: 0.305895\n",
      "Epoch 04 | Train MSE: 0.277576 | Val MSE: 0.293964\n",
      "Epoch 05 | Train MSE: 0.272414 | Val MSE: 0.287569\n",
      "Epoch 06 | Train MSE: 0.269627 | Val MSE: 0.283831\n",
      "Epoch 07 | Train MSE: 0.267156 | Val MSE: 0.281605\n",
      "Epoch 08 | Train MSE: 0.264132 | Val MSE: 0.280177\n",
      "Epoch 09 | Train MSE: 0.259965 | Val MSE: 0.279137\n",
      "Epoch 10 | Train MSE: 0.254642 | Val MSE: 0.278652\n",
      "Epoch 11 | Train MSE: 0.248841 | Val MSE: 0.279565\n",
      "Epoch 12 | Train MSE: 0.243415 | Val MSE: 0.282555\n",
      "Epoch 13 | Train MSE: 0.238910 | Val MSE: 0.287118\n",
      "Epoch 14 | Train MSE: 0.235493 | Val MSE: 0.292534\n",
      "Epoch 15 | Train MSE: 0.232965 | Val MSE: 0.299421\n",
      "Epoch 16 | Train MSE: 0.230910 | Val MSE: 0.307244\n",
      "Epoch 17 | Train MSE: 0.228883 | Val MSE: 0.312302\n",
      "Epoch 18 | Train MSE: 0.226661 | Val MSE: 0.316111\n",
      "Epoch 19 | Train MSE: 0.224375 | Val MSE: 0.320946\n",
      "Epoch 20 | Train MSE: 0.222200 | Val MSE: 0.326900\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# ============================================================\n",
    "# 1. LSTM CLASS (WITH BPTT)\n",
    "# ============================================================\n",
    "class LSTM:\n",
    "    def __init__(self, input_size, hidden_size, learning_rate):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.total_input = input_size + hidden_size\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        # States\n",
    "        self.h = np.zeros(hidden_size)\n",
    "        self.c = np.zeros(hidden_size)\n",
    "\n",
    "        # Weights\n",
    "        self.Wf = np.random.randn(hidden_size, self.total_input) * 0.1\n",
    "        self.Wi = np.random.randn(hidden_size, self.total_input) * 0.1\n",
    "        self.Wc = np.random.randn(hidden_size, self.total_input) * 0.1\n",
    "        self.Wo = np.random.randn(hidden_size, self.total_input) * 0.1\n",
    "\n",
    "        self.Wy = np.random.randn(input_size, hidden_size) * 0.1\n",
    "        self.by = np.zeros(input_size)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "\n",
    "    def dsigmoid(self, y):\n",
    "        return y * (1 - y)\n",
    "\n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def dtanh(self, y):\n",
    "        return 1 - y ** 2\n",
    "\n",
    "    # ----------------------------\n",
    "    # FORWARD PASS\n",
    "    # ----------------------------\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.z = np.concatenate([self.h, x])\n",
    "\n",
    "        self.f = self.sigmoid(np.dot(self.Wf, self.z))\n",
    "        self.i = self.sigmoid(np.dot(self.Wi, self.z))\n",
    "        self.c_hat = self.tanh(np.dot(self.Wc, self.z))\n",
    "        self.o = self.sigmoid(np.dot(self.Wo, self.z))\n",
    "\n",
    "        self.c_prev = self.c.copy()\n",
    "        self.c = self.f * self.c + self.i * self.c_hat\n",
    "        self.h = self.o * self.tanh(self.c)\n",
    "\n",
    "        y_pred = np.dot(self.Wy, self.h) + self.by\n",
    "        return y_pred\n",
    "\n",
    "    # ----------------------------\n",
    "    # BACKPROP (1-STEP BPTT)\n",
    "    # ----------------------------\n",
    "    def backward(self, y_pred, y_true):\n",
    "        dy = y_pred - y_true  # d(MSE)/dy\n",
    "\n",
    "        dWy = np.outer(dy, self.h)\n",
    "        dby = dy\n",
    "\n",
    "        dh = np.dot(self.Wy.T, dy)\n",
    "        do = dh * self.tanh(self.c)\n",
    "        do *= self.dsigmoid(self.o)\n",
    "\n",
    "        dc = dh * self.o * self.dtanh(self.tanh(self.c))\n",
    "        dc += self.f * 0  # truncated BPTT\n",
    "\n",
    "        df = dc * self.c_prev\n",
    "        df *= self.dsigmoid(self.f)\n",
    "\n",
    "        di = dc * self.c_hat\n",
    "        di *= self.dsigmoid(self.i)\n",
    "\n",
    "        dc_hat = dc * self.i\n",
    "        dc_hat *= self.dtanh(self.c_hat)\n",
    "\n",
    "        dWf = np.outer(df, self.z)\n",
    "        dWi = np.outer(di, self.z)\n",
    "        dWc = np.outer(dc_hat, self.z)\n",
    "        dWo = np.outer(do, self.z)\n",
    "\n",
    "        # ----------------------------\n",
    "        # WEIGHT UPDATE\n",
    "        # ----------------------------\n",
    "        self.Wy -= self.lr * dWy\n",
    "        self.by -= self.lr * dby\n",
    "        self.Wf -= self.lr * dWf\n",
    "        self.Wi -= self.lr * dWi\n",
    "        self.Wc -= self.lr * dWc\n",
    "        self.Wo -= self.lr * dWo\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. LOAD & NORMALIZE DATA\n",
    "# ============================================================\n",
    "def load_accelerometer_data(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(\"accelerometer.csv not found\")\n",
    "\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                data.append([float(row[1]), float(row[2]), float(row[3])])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    data = np.array(data)\n",
    "    data = (data - data.mean(axis=0)) / (data.std(axis=0) + 1e-8)\n",
    "    return data\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. TRAIN + VALIDATION\n",
    "# ============================================================\n",
    "def train_lstm():\n",
    "    data = load_accelerometer_data(\"accelerometer.csv\")\n",
    "\n",
    "    split = int(0.8 * len(data))\n",
    "    train_data = data[:split]\n",
    "    val_data = data[split:]\n",
    "\n",
    "    model = LSTM(input_size=3, hidden_size=50, learning_rate=0.001)\n",
    "    epochs = 20\n",
    "\n",
    "    print(\"\\n--- Training LSTM ---\\n\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "\n",
    "        model.h[:] = 0\n",
    "        model.c[:] = 0\n",
    "\n",
    "        for t in range(len(train_data) - 1):\n",
    "            x = train_data[t]\n",
    "            y_true = train_data[t + 1]\n",
    "\n",
    "            y_pred = model.forward(x)\n",
    "            loss = np.mean((y_pred - y_true) ** 2)\n",
    "            train_loss += loss\n",
    "\n",
    "            model.backward(y_pred, y_true)\n",
    "\n",
    "        train_loss /= len(train_data)\n",
    "\n",
    "        # ----------------------------\n",
    "        # VALIDATION\n",
    "        # ----------------------------\n",
    "        val_loss = 0\n",
    "        model.h[:] = 0\n",
    "        model.c[:] = 0\n",
    "\n",
    "        for t in range(len(val_data) - 1):\n",
    "            y_pred = model.forward(val_data[t])\n",
    "            val_loss += np.mean((y_pred - val_data[t + 1]) ** 2)\n",
    "\n",
    "        val_loss /= len(val_data)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d} | Train MSE: {train_loss:.6f} | Val MSE: {val_loss:.6f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. MAIN\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    train_lstm()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
